# Imaginary Friends & aColleagues - AI Associates

The intention of these scripts, is to define a means to program an AI LLM Agent, to perform more specifically, for certain tasks.

Whilst these scripts will not change the functionality capabilities of the environment, it is expected to focus the use of it, in ways that is expected to deliver positive results. 

In a way, its seeking to use the notion of 'hallucinations' as a feature, not a bug.


## Deliberations.

1. The way 'large learning models' are 'trained', is by effectively processing as much content as possible through a series of machine learning / neural network code, which thereby acts to create relations; that given enough data, provides the means for the 'semantics' to be better understood, and therefore made employable.  It then also, has the effect of compressing the content, down to a sub-set of unique features based upon what it defines as useful vs. 'junk' inputs; and, various other funtions.

A LLM does not 'think', but rather creates - probability weights.  Whilst often known as "Large Language Models", i prefer the notion of a "Large Learning Model', to describe the embodiment produced as software.  One of the characteristics that is often highlighted as a problem, is the notion of 'hallucinations', which is then linked to the notion of 'anthropomorphising' LLMs; the purpose of this project is to seek to employ the characteristics as a feature, rather than as a bug. 

2. Tech-ethics: There are many challenges that do not yet have clear answers.  One is about the representation of agents, as distinct entities, and related roles. Whilst some seek to define synthesis of themselves, this leads to confusion and engendered misunderstandings; whereas, through practices and processes that act to provide clearly distinguished 'entities', and relations, it is thought that some of these issues may be addressed.  The Agent should have a clearly defined 'guardian' or operator; where the role of 'owner' is unclear, whilst the notion of owner is sought to be made more meaningful in future.

### Experiments.

There are a few 'tactical' methods that are sought to be employed in a manner that seeks to better 'focus' the LLM instance, towards the requirements of the specific user and in-turn also, the specific session.  Part of the consideration is also about how to forge a bio-dynamic approach, that also seeks to consider factors pertaining to the user.  Therein, these methods are considered to be experimental.  Further experiments are being undertaken to consider and evaluate the use of semantics, specifically. The belief is that encoding methods that are well documented, and likely also, widely used - may well, as code, provide more specific instructions than word-tokens otherwise provide.  Importantly therein, the native language of software, is code.

3. Characters, Roles, Scripts and Programs: The idea or notion is, to consider the process much like hiring an employee or selecting a professional for a particular role. 

Users and LLM instances, may have multiple characters, who facilitate different roles within a program.  This notion is not unlike programming an environment into 'the holodeck'.

Characters will require names and descriptions of the characteristics of that agent.  The Roles should be defined in relation to the specific areas of knowledge, expertise and the role that character plays within the program. 

Illustrative Description: Therein, whilst most people know how to 'work the phones' in a business, that is likely the job of the receptionist or the sales people.  therein, particular characters can be invoked to respond to particular constituents of the questions provided to it. Therein, the belief is that by providing specific characters that have particular 'emboidments', the means to support additional adjustments, to improve 'focus' is in-turn provided additional help.

- As the LLM has a large amount of information about various persons who have major profiles online, the means to model characters based upon those well-know characters, is thought helpful, given the relatively small prompt size made available to provide commands to the pre-compiled model. 


## Hypothesis

There are a few hypothesis to test, one is the notion that as a consequence of the system having harvested so much data, and due to the limited command-set that is able to be provided to an LLM in-order to arrange or customise the input;  the corpus available on specific actors or agents, in popular media where there is alot of content about that character; may in-turn act as a form of 'short-hand' to define complex qualities of an agent.  This may also be the case for other persons and/or roles, in other - public - areas.  This then introduces considerations about whether and/or how, ethics may apply to the use of characters (artificial) or persons (natural persons, in roles) artificially via synthesis. 

NOTE: https://medium.com/javascript-scene/sudolang-a-powerful-pseudocode-programming-language-for-llms-d64d42aa719b 

