# LLM Disinformation & MisInformation 

Generally speaking, i don't like the term 'mis' or 'dis' (or 'mal') information as its still information, just not knowledge. not properly classified as to form it as a form of knowledge.  Yet, this is in-turn also, about modal adjustments and related factorization of informatics, as to engender attributes sufficient as to address the problem; so, given that's hard sometimes - and an LLM isn't the same as a natural person, lets go with the terms for that purpose.

## Problem Statement

Whilst working on how to extract better information out of LLMs, i started to think about the way different information or answers are provided by different models, in more detail.  

https://x.com/jahendler/status/1031005656457900032 

Recently, the type of experience described by Jim occurred to me; and, perhaps this is what prompted it.  but the examination was in relation to another industry leader, indeed, another elder akin to Jim, but in a different field.  When i was testing LLMs, i tried using this persons name to see what came back, and all the responses were misleading containing false statements; both with real entities and another that i think may be imaginary.  I found this was intriguing, and then also tested it again on myself, and saw similar issues, however the output was relatively good on a major LLM, not that this is always the case...

But then thinking about it; in the context, of defining 'assistants', etc.  I started to consider the implications when and/or if the vast majority are relying upon these tools as part of their business work-flow.  I wondered whether some recent experiences, may in-fact relate to actions that were taken based on false beliefs engendered upon lower-ranking administrative staff, who then went about curating activities or actions based upon & in reliance of, that information, believing it to be correct.



